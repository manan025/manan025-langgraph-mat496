{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "319adfec-2d0a-49f2-87f9-275c4a32add2",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "## Review\n",
    "\n",
    "In module 2, covered a few ways to customize graph state and memory.\n",
    " \n",
    "We built up to a Chatbot with external memory that can sustain long-running conversations. \n",
    "\n",
    "## Goals\n",
    "\n",
    "This module will dive into `human-in-the-loop`, which builds on memory and allows users to interact directly with graphs in various ways. \n",
    "\n",
    "To set the stage for `human-in-the-loop`, we'll first dive into streaming, which provides several ways to visualize graph output (e.g., node state or chat model tokens) over the course of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db024d1f-feb3-45a0-a55c-e7712a1feefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langgraph langchain_openai langgraph_sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7e41b-c6ba-4e47-b645-6c110bede549",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "LangGraph is built with [first class support for streaming](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "Let's set up our Chatbot from Module 2, and show various way to stream outputs from the graph during execution. "
   ]
  },
  {
   "cell_type": "code",
   "id": "5b430d92-f595-4322-a56e-06de7485daa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:47:46.109113Z",
     "start_time": "2025-12-11T05:47:46.103617Z"
    }
   },
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"ANTHROPIC_API_KEY\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "4d0682fc",
   "metadata": {},
   "source": [
    "Note that we use `RunnableConfig` with `call_model` to enable token-wise streaming. This is [only needed with python < 3.11](https://langchain-ai.github.io/langgraph/how-tos/streaming-tokens/). We include in case you are running this notebook in CoLab, which will use python 3.x. "
   ]
  },
  {
   "cell_type": "code",
   "id": "2d7321e0-0d99-4efe-a67b-74c12271859b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:48:17.346997Z",
     "start_time": "2025-12-11T05:48:16.578176Z"
    }
   },
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# LLM\n",
    "model = ChatAnthropic(model_name=\"claude-haiku-4-5\", max_tokens=1024, temperature=0)\n",
    "\n",
    "# State \n",
    "class State(MessagesState):\n",
    "    summary: str\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State, config: RunnableConfig):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages, config)\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}\n",
    "\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ],
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f847a787-b301-488c-9b58-cba9f389f55d",
   "metadata": {},
   "source": [
    "### Streaming full state\n",
    "\n",
    "Now, let's talk about ways to [stream our graph state](https://langchain-ai.github.io/langgraph/concepts/low_level/#streaming).\n",
    "\n",
    "`.stream` and `.astream` are sync and async methods for streaming back results. \n",
    " \n",
    "LangGraph supports a few [different streaming modes](https://langchain-ai.github.io/langgraph/how-tos/stream-values/) for [graph state](https://langchain-ai.github.io/langgraph/how-tos/stream-values/):\n",
    " \n",
    "* `values`: This streams the full state of the graph after each node is called.\n",
    "* `updates`: This streams updates to the state of the graph after each node is called.\n",
    "\n",
    "![values_vs_updates.png](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbaf892d24625a201744e5_streaming1.png)\n",
    "\n",
    "Let's look at `stream_mode=\"updates\"`.\n",
    "\n",
    "Because we stream with `updates`, we only see updates to the state after node in the graph is run.\n",
    "\n",
    "Each `chunk` is a dict with `node_name` as the key and the updated state as the value."
   ]
  },
  {
   "cell_type": "code",
   "id": "9a6f8ae9-f244-40c5-a2da-618b72631b22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:48:22.017581Z",
     "start_time": "2025-12-11T05:48:20.675229Z"
    }
   },
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    print(chunk)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conversation': {'messages': AIMessage(content=\"Hey Lance! Nice to meet you. How's it going? What can I help you with today?\", additional_kwargs={}, response_metadata={'id': 'msg_01Y3TGqj85n2eT6zLjDbCfD6', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 12, 'output_tokens': 24, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'}, id='run--6ecff489-add7-414d-baa6-240d2b927fe6-0', usage_metadata={'input_tokens': 12, 'output_tokens': 24, 'total_tokens': 36, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}})}}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "0c4882e9-07dd-4d70-866b-dfc530418cad",
   "metadata": {},
   "source": [
    "Let's now just print the state update."
   ]
  },
  {
   "cell_type": "code",
   "id": "c859c777-cb12-4682-9108-6b367e597b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:48:24.019107Z",
     "start_time": "2025-12-11T05:48:23.024111Z"
    }
   },
   "source": [
    "# Start conversation\n",
    "for chunk in graph.stream({\"messages\": [HumanMessage(content=\"hi! I'm Lance\")]}, config, stream_mode=\"updates\"):\n",
    "    chunk['conversation'][\"messages\"].pretty_print()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hey Lance! Good to see you again. ðŸ‘‹ Is there something I can help you with, or did you just want to chat?\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "583bf219-6358-4d06-ae99-c40f43569fda",
   "metadata": {},
   "source": [
    "Now, we can see `stream_mode=\"values\"`.\n",
    "\n",
    "This is the `full state` of the graph after the `conversation` node is called."
   ]
  },
  {
   "cell_type": "code",
   "id": "6ee763f8-6d1f-491e-8050-fb1439e116df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:48:27.111079Z",
     "start_time": "2025-12-11T05:48:25.383223Z"
    }
   },
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "for event in graph.stream({\"messages\": [input_message]}, config, stream_mode=\"values\"):\n",
    "    for m in event['messages']:\n",
    "        m.pretty_print()\n",
    "    print(\"---\"*25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "---------------------------------------------------------------------------\n",
      "================================\u001B[1m Human Message \u001B[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001B[1m Ai Message \u001B[0m==================================\n",
      "\n",
      "Hey Lance! Nice to meet you. How's it going? What can I help you with today?\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "563c198a-d1a4-4700-b7a7-ff5b8e0b25d7",
   "metadata": {},
   "source": [
    "### Streaming tokens\n",
    "\n",
    "We often want to stream more than graph state.\n",
    "\n",
    "In particular, with chat model calls it is common to stream the tokens as they are generated.\n",
    "\n",
    "We can do this [using the `.astream_events` method](https://langchain-ai.github.io/langgraph/how-tos/streaming-from-final-node/#stream-outputs-from-the-final-node), which streams back events as they happen inside nodes!\n",
    "\n",
    "Each event is a dict with a few keys:\n",
    " \n",
    "* `event`: This is the type of event that is being emitted. \n",
    "* `name`: This is the name of event.\n",
    "* `data`: This is the data associated with the event.\n",
    "* `metadata`: Contains`langgraph_node`, the node emitting the event.\n",
    "\n",
    "Let's have a look."
   ]
  },
  {
   "cell_type": "code",
   "id": "6ae8c7a6-c6e7-4cef-ac9f-190d2f4dd763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:48:31.480947Z",
     "start_time": "2025-12-11T05:48:27.321280Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    print(f\"Node: {event['metadata'].get('langgraph_node','')}. Type: {event['event']}. Name: {event['name']}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node: . Type: on_chain_start. Name: LangGraph\n",
      "Node: conversation. Type: on_chain_start. Name: conversation\n",
      "Node: conversation. Type: on_chat_model_start. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_stream. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chat_model_end. Name: ChatAnthropic\n",
      "Node: conversation. Type: on_chain_start. Name: should_continue\n",
      "Node: conversation. Type: on_chain_end. Name: should_continue\n",
      "Node: conversation. Type: on_chain_stream. Name: conversation\n",
      "Node: conversation. Type: on_chain_end. Name: conversation\n",
      "Node: . Type: on_chain_stream. Name: LangGraph\n",
      "Node: . Type: on_chain_end. Name: LangGraph\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "0b63490f-3d24-4f68-95ca-5320ccb61d2d",
   "metadata": {},
   "source": [
    "The central point is that tokens from chat models within your graph have the `on_chat_model_stream` type.\n",
    "\n",
    "We can use `event['metadata']['langgraph_node']` to select the node to stream from.\n",
    "\n",
    "And we can use `event['data']` to get the actual data for each event, which in this case is an `AIMessageChunk`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3529f8-3960-4d41-9ed6-373f93183950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': AIMessageChunk(content='', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' professional', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' American', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' based', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bay', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Area', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' compete', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' National', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' League', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=')', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' as', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' member', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' league', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' National', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='N', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='FC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=')', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' West', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' division', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Here', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' some', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' key', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' points', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' about', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' History', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Founded', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='194', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='6', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Joined', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='194', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='9', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' as', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' part', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' merger', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' between', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' All', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-Amer', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ica', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Football', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Conference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='AA', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='FC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=')\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Name', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Origin', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' name', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' \"', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\"', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' is', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' reference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' prospect', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ors', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' who', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' arrived', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Northern', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' California', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' during', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='184', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='9', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Gold', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rush', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Ach', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ievements', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' won', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' five', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' titles', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' (', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='X', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='VI', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XIX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='III', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='IV', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' XX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='IX', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=').\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Conference', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' won', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championship', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' seven', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' times', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Division', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Championships', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' has', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' numerous', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFC', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' West', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' division', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' titles', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Not', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='able', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Figures', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Joe', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Montana', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' who', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' led', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' four', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' victories', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Jerry', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rice', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Wid', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ely', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' considered', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' greatest', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' wide', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' receiver', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' history', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Steve', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Young', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Another', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Hall', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Fame', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' quarterback', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' who', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' led', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' victory', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Bill', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Walsh', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Legendary', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' head', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' coach', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' known', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' developing', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' \"', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='West', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Coast', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Off', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ense', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\"\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Home', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Le', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='vi', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=\"'s\", id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Stadium', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Located', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Santa', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Clara', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' California', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' it', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' has', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' been', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=\" team's\", id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' home', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' since', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='201', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='4', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Prior', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' to', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' that', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' they', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' played', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' at', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Cand', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='lestick', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Park', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Colors', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Masc', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ot', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Colors', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Red', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' gold', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' white', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='-', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' **', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Masc', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ot', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=':**', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' S', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ourd', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ough', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Sam', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Recent', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Performance', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' experienced', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' various', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' periods', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' success', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rebuilding', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' reached', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Super', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Bowl', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='201', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='9', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' season', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' but', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' were', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' defeated', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' by', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Kansas', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' City', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Chiefs', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' team', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' has', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' been', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' competitive', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' recent', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' years', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' often', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' cont', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ending', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' playoff', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' spots', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Community', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Culture', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' a', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' strong', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' fan', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' base', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' known', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' their', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rich', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' history', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' tradition', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' They', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' also', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' active', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' community', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' service', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' charitable', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' activities', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' through', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Foundation', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='###', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rival', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ries', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='The', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' have', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' notable', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rival', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ries', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' with', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' several', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' teams', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' including', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Dallas', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Cowboys', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Seattle', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Seahawks', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Los', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Angeles', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Rams', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' These', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' rival', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ries', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' often', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' marked', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' by', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' intense', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' memorable', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' games', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.\\n\\n', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='Overall', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' San', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' Francisco', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='49', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ers', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' are', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' one', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' most', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' stor', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='ied', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' franchises', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' NFL', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' history', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=',', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' known', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' for', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' their', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' success', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' in', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='198', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='0', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='s', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' ', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='199', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='0', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='s', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' and', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' their', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' continued', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' pursuit', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' of', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' excellence', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' on', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' the', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content=' field', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='.', id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n",
      "{'chunk': AIMessageChunk(content='', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_25624ae3a5'}, id='run-b76ec3b8-9c45-42fe-b321-4ec3a69c185c')}\n"
     ]
    }
   ],
   "source": [
    "node_to_stream = 'conversation'\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        print(event[\"data\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e569a-76c3-43d8-8f89-3ae687efde1c",
   "metadata": {},
   "source": [
    "As you see above, just use the `chunk` key to get the `AIMessageChunk`."
   ]
  },
  {
   "cell_type": "code",
   "id": "3aeae53d-6dcf-40d0-a0c6-c40de492cc83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T06:03:39.060308Z",
     "start_time": "2025-12-11T06:03:37.435517Z"
    }
   },
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "input_message = HumanMessage(content=\"Tell me about the 49ers NFL team\")\n",
    "async for event in graph.astream_events({\"messages\": [input_message]}, config, version=\"v2\"):\n",
    "    # Get chat model tokens from a particular node \n",
    "    if event[\"event\"] == \"on_chat_model_stream\" and event['metadata'].get('langgraph_node','') == node_to_stream:\n",
    "        data = event[\"data\"]\n",
    "        print(data[\"chunk\"].content, end=\"|\")"
   ],
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'node_to_stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[19]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m input_message = HumanMessage(content=\u001B[33m\"\u001B[39m\u001B[33mTell me about the 49ers NFL team\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m event \u001B[38;5;129;01min\u001B[39;00m graph.astream_events({\u001B[33m\"\u001B[39m\u001B[33mmessages\u001B[39m\u001B[33m\"\u001B[39m: [input_message]}, config, version=\u001B[33m\"\u001B[39m\u001B[33mv2\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m      4\u001B[39m     \u001B[38;5;66;03m# Get chat model tokens from a particular node \u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m event[\u001B[33m\"\u001B[39m\u001B[33mevent\u001B[39m\u001B[33m\"\u001B[39m] == \u001B[33m\"\u001B[39m\u001B[33mon_chat_model_stream\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m event[\u001B[33m'\u001B[39m\u001B[33mmetadata\u001B[39m\u001B[33m'\u001B[39m].get(\u001B[33m'\u001B[39m\u001B[33mlanggraph_node\u001B[39m\u001B[33m'\u001B[39m,\u001B[33m'\u001B[39m\u001B[33m'\u001B[39m) == \u001B[43mnode_to_stream\u001B[49m:\n\u001B[32m      6\u001B[39m         data = event[\u001B[33m\"\u001B[39m\u001B[33mdata\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m      7\u001B[39m         \u001B[38;5;28mprint\u001B[39m(data[\u001B[33m\"\u001B[39m\u001B[33mchunk\u001B[39m\u001B[33m\"\u001B[39m].content, end=\u001B[33m\"\u001B[39m\u001B[33m|\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'node_to_stream' is not defined"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Streaming Mode Comparison\n",
    "\n",
    "Let's compare different streaming modes to understand when to use each one."
   ],
   "id": "ff3230ace1bfdf4e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Comparison: updates vs values streaming\n",
    "config_comparison = {\"configurable\": {\"thread_id\": \"6\"}}\n",
    "input_message = HumanMessage(content=\"What's the weather like?\")\n",
    "\n",
    "print(\"STREAMING WITH 'updates' MODE:\")\n",
    "print(\"=\" * 70)\n",
    "for chunk in graph.stream({\"messages\": [input_message]}, config_comparison, stream_mode=\"updates\"):\n",
    "    print(f\"Node: {list(chunk.keys())[0]}\")\n",
    "    print(f\"Update: {chunk}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "print(\"\\n\\nSTREAMING WITH 'values' MODE:\")\n",
    "print(\"=\" * 70)\n",
    "config_comparison2 = {\"configurable\": {\"thread_id\": \"7\"}}\n",
    "for event in graph.stream({\"messages\": [input_message]}, config_comparison2, stream_mode=\"values\"):\n",
    "    print(f\"Full State: {len(event['messages'])} messages\")\n",
    "    print(f\"Latest message: {event['messages'][-1].content[:50]}...\")\n",
    "    print(\"-\" * 70)"
   ],
   "id": "c05450f6936847c2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Extracting Specific Event Data\n",
    "\n",
    "Let's create a helper to extract and display only the information we care about from streaming events."
   ],
   "id": "1e0be823ad069f7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "async def stream_and_extract_metadata(graph, input_msg, config):\n",
    "    \"\"\"\n",
    "    Stream events and extract only key metadata like model name, tokens used, and timing.\n",
    "    \"\"\"\n",
    "    print(\"Streaming with metadata extraction:\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    async for event in graph.astream_events({\"messages\": [input_msg]}, config, version=\"v2\"):\n",
    "        # Extract model information\n",
    "        if event[\"event\"] == \"on_chat_model_start\":\n",
    "            node = event['metadata'].get('langgraph_node', 'unknown')\n",
    "            print(f\"ðŸ¤– Model started in node: {node}\")\n",
    "\n",
    "        # Extract token streaming\n",
    "        elif event[\"event\"] == \"on_chat_model_stream\":\n",
    "            node = event['metadata'].get('langgraph_node', '')\n",
    "            if node == 'conversation':\n",
    "                content = event[\"data\"][\"chunk\"].content\n",
    "                if content:\n",
    "                    print(content, end=\"\", flush=True)\n",
    "\n",
    "        # Extract completion info\n",
    "        elif event[\"event\"] == \"on_chat_model_end\":\n",
    "            node = event['metadata'].get('langgraph_node', 'unknown')\n",
    "            print(f\"\\nâœ… Model completed in node: {node}\")\n",
    "            print(\"-\" * 70)\n",
    "\n",
    "# Test the helper\n",
    "config_extract = {\"configurable\": {\"thread_id\": \"8\"}}\n",
    "input_message = HumanMessage(content=\"Tell me a short joke about programming\")\n",
    "await stream_and_extract_metadata(graph, input_message, config_extract)"
   ],
   "id": "38aa75974b0822f2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Streaming with LangGraph API\n",
    "\n",
    "**âš ï¸ DISCLAIMER**\n",
    "\n",
    "Since the filming of these videos, we've updated Studio so that it can be run locally and opened in your browser. This is now the preferred way to run Studio (rather than using the Desktop App as shown in the video). See documentation [here](https://langchain-ai.github.io/langgraph/concepts/langgraph_studio/#local-development-server) on the local development server and [here](https://langchain-ai.github.io/langgraph/how-tos/local-studio/#run-the-development-server). To start the local development server, run the following command in your terminal in the `/studio` directory in this module:\n",
    "\n",
    "```\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see the following output:\n",
    "```\n",
    "- ðŸš€ API: http://127.0.0.1:2024\n",
    "- ðŸŽ¨ Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "- ðŸ“š API Docs: http://127.0.0.1:2024/docs\n",
    "```\n",
    "\n",
    "Open your browser and navigate to the Studio UI: `https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024`.\n",
    "\n",
    "The LangGraph API [supports editing graph state](https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_edit_state/#initial-invocation). "
   ],
   "id": "3ca950fb285e8c0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925b632-512b-48e1-9220-61c06bfbf0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    raise Exception(\"Unfortunately LangGraph Studio is currently not supported on Google Colab\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "079c2ad6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:50:41.346770Z",
     "start_time": "2025-12-11T05:50:41.303581Z"
    }
   },
   "source": [
    "from langgraph_sdk import get_client\n",
    "\n",
    "# This is the URL of the local development server\n",
    "URL = \"http://localhost:2024\"\n",
    "client = get_client(url=URL)\n",
    "\n",
    "# Search all hosted graphs\n",
    "assistants = await client.assistants.search()"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "4d15af9e-0e86-41e3-a5ba-ee2a4aa08a32",
   "metadata": {},
   "source": [
    "Let's [stream `values`](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_values/), like before."
   ]
  },
  {
   "cell_type": "code",
   "id": "63e3096f-5429-4d3c-8de2-2bddf7266ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:50:46.692417Z",
     "start_time": "2025-12-11T05:50:43.688401Z"
    }
   },
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "# Input message\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"values\"):\n",
    "    print(event)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StreamPart(event='metadata', data={'run_id': '019b0bf6-35ef-7148-a65b-b664423e637d', 'attempt': 1})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '25e859a1-5198-40b6-8cc4-8b3ef94f7bd9', 'example': False}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '25e859a1-5198-40b6-8cc4-8b3ef94f7bd9', 'example': False}, {'content': [{'id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'input': {'a': 2, 'b': 3}, 'name': 'multiply', 'type': 'tool_use'}], 'additional_kwargs': {}, 'response_metadata': {'id': 'msg_01VCVu2vMb36nfeXUpWyCBoK', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 764, 'output_tokens': 69, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'}, 'type': 'ai', 'name': None, 'id': 'run--d4f7dfc3-1b96-43d9-9242-9df8d37cb98b-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 764, 'output_tokens': 69, 'total_tokens': 833, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '25e859a1-5198-40b6-8cc4-8b3ef94f7bd9', 'example': False}, {'content': [{'id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'input': {'a': 2, 'b': 3}, 'name': 'multiply', 'type': 'tool_use'}], 'additional_kwargs': {}, 'response_metadata': {'id': 'msg_01VCVu2vMb36nfeXUpWyCBoK', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 764, 'output_tokens': 69, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'}, 'type': 'ai', 'name': None, 'id': 'run--d4f7dfc3-1b96-43d9-9242-9df8d37cb98b-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 764, 'output_tokens': 69, 'total_tokens': 833, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'bd53d833-8840-4713-b215-9001ef2575f5', 'tool_call_id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'artifact': None, 'status': 'success'}]})\n",
      "StreamPart(event='values', data={'messages': [{'content': 'Multiply 2 and 3', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '25e859a1-5198-40b6-8cc4-8b3ef94f7bd9', 'example': False}, {'content': [{'id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'input': {'a': 2, 'b': 3}, 'name': 'multiply', 'type': 'tool_use'}], 'additional_kwargs': {}, 'response_metadata': {'id': 'msg_01VCVu2vMb36nfeXUpWyCBoK', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 764, 'output_tokens': 69, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'}, 'type': 'ai', 'name': None, 'id': 'run--d4f7dfc3-1b96-43d9-9242-9df8d37cb98b-0', 'example': False, 'tool_calls': [{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'type': 'tool_call'}], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 764, 'output_tokens': 69, 'total_tokens': 833, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}}, {'content': '6', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'tool', 'name': 'multiply', 'id': 'bd53d833-8840-4713-b215-9001ef2575f5', 'tool_call_id': 'toolu_01GbqYjWjgw4TqrkQXZg8xW1', 'artifact': None, 'status': 'success'}, {'content': 'The result of multiplying 2 and 3 is **6**.', 'additional_kwargs': {}, 'response_metadata': {'id': 'msg_01Y9xaemjBJf5WNrCAvSfMq3', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 846, 'output_tokens': 19, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'}, 'type': 'ai', 'name': None, 'id': 'run--fbd60e1c-57b9-4d71-a950-49faeee486b0-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 846, 'output_tokens': 19, 'total_tokens': 865, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}}]})\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "556dc7fd-1cae-404f-816a-f13d772b3b14",
   "metadata": {},
   "source": [
    "The streamed objects have: \n",
    "\n",
    "* `event`: Type\n",
    "* `data`: State"
   ]
  },
  {
   "cell_type": "code",
   "id": "57b735aa-139c-45a3-a850-63519c0004f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:50:52.115020Z",
     "start_time": "2025-12-11T05:50:49.516135Z"
    }
   },
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], assistant_id=\"agent\", input={\"messages\": [input_message]}, stream_mode=\"values\"):\n",
    "    messages = event.data.get('messages',None)\n",
    "    if messages:\n",
    "        print(convert_to_messages(messages)[-1])\n",
    "    print('='*25)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================\n",
      "content='Multiply 2 and 3' additional_kwargs={} response_metadata={} id='240d5638-6e3f-417f-b8b6-d8182f910f75'\n",
      "=========================\n",
      "content=[{'id': 'toolu_01RwyRHmQ5emQb16pRJD2VMo', 'input': {'a': 2, 'b': 3}, 'name': 'multiply', 'type': 'tool_use'}] additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 764, 'output_tokens': 69, 'total_tokens': 833, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}} response_metadata={'id': 'msg_019qbqLuUSe2wD1w7PjFeuMh', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 764, 'output_tokens': 69, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'} id='run--32a3c06a-8a5c-4f2d-9acd-b63efe8ecba7-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'toolu_01RwyRHmQ5emQb16pRJD2VMo', 'type': 'tool_call'}]\n",
      "=========================\n",
      "content='6' name='multiply' id='5e55333c-980d-4e9c-96f7-f50cb4039ec0' tool_call_id='toolu_01RwyRHmQ5emQb16pRJD2VMo'\n",
      "=========================\n",
      "content='The result of multiplying 2 and 3 is **6**.' additional_kwargs={'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 846, 'output_tokens': 19, 'total_tokens': 865, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}} response_metadata={'id': 'msg_01EosBoZpjZVKAhdAEFzanw4', 'model': 'claude-haiku-4-5-20251001', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 846, 'output_tokens': 19, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-haiku-4-5-20251001'} id='run--6d68e009-f4d6-4a7e-8b84-cd57b9283683-0'\n",
      "=========================\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "a555d186-27be-4ddf-934c-895a3105035d",
   "metadata": {},
   "source": [
    "There are some new streaming mode that are only supported via the API.\n",
    "\n",
    "For example, we can [use `messages` mode](https://langchain-ai.github.io/langgraph/cloud/how-tos/stream_messages/) to better handle the above case!\n",
    "\n",
    "This mode currently assumes that you have a `messages` key in your graph, which is a list of messages.\n",
    "\n",
    "All events emitted using `messages` mode have two attributes:\n",
    "\n",
    "* `event`: This is the name of the event\n",
    "* `data`: This is data associated with the event"
   ]
  },
  {
   "cell_type": "code",
   "id": "4abd91f6-63c0-41ee-9988-7c8248b88a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T05:50:59.945163Z",
     "start_time": "2025-12-11T05:50:57.266306Z"
    }
   },
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "async for event in client.runs.stream(thread[\"thread_id\"], \n",
    "                                      assistant_id=\"agent\", \n",
    "                                      input={\"messages\": [input_message]}, \n",
    "                                      stream_mode=\"messages\"):\n",
    "    print(event.event)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/metadata\n",
      "messages/complete\n",
      "messages/metadata\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n",
      "messages/partial\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "8de2f1ea-b232-43fc-af7a-320efce83381",
   "metadata": {},
   "source": [
    "We can see a few events: \n",
    "\n",
    "* `metadata`: metadata about the run\n",
    "* `messages/complete`: fully formed message \n",
    "* `messages/partial`: chat model tokens\n",
    "\n",
    "You can dig further into the types [here](https://langchain-ai.github.io/langgraph/cloud/concepts/api/#modemessages).\n",
    "\n",
    "Now, let's show how to stream these messages. \n",
    "\n",
    "We'll define a helper function for better formatting of the tool calls in messages."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "thread = await client.threads.create()\n",
    "input_message = HumanMessage(content=\"Multiply 2 and 3\")\n",
    "\n",
    "def format_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Format a list of tool calls into a readable string.\n",
    "\n",
    "    Args:\n",
    "        tool_calls (list): A list of dictionaries, each representing a tool call.\n",
    "            Each dictionary should have 'id', 'name', and 'args' keys.\n",
    "\n",
    "    Returns:\n",
    "        str: A formatted string of tool calls, or \"No tool calls\" if the list is empty.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if tool_calls:\n",
    "        formatted_calls = []\n",
    "        for call in tool_calls:\n",
    "            formatted_calls.append(\n",
    "                f\"Tool Call ID: {call['id']}, Function: {call['name']}, Arguments: {call['args']}\"\n",
    "            )\n",
    "        return \"\\n\".join(formatted_calls)\n",
    "    return \"No tool calls\"\n",
    "\n",
    "async for event in client.runs.stream(\n",
    "    thread[\"thread_id\"],\n",
    "    assistant_id=\"agent\",\n",
    "    input={\"messages\": [input_message]},\n",
    "    stream_mode=\"messages\",):\n",
    "    \n",
    "    # Handle metadata events\n",
    "    if event.event == \"metadata\":\n",
    "        print(f\"Metadata: Run ID - {event.data['run_id']}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    # Handle partial message events\n",
    "    elif event.event == \"messages/partial\":\n",
    "        for data_item in event.data:\n",
    "            # Process user messages\n",
    "            if \"role\" in data_item and data_item[\"role\"] == \"user\":\n",
    "                print(f\"Human: {data_item['content']}\")\n",
    "            else:\n",
    "                # Extract relevant data from the event\n",
    "                tool_calls = data_item.get(\"tool_calls\", [])\n",
    "                invalid_tool_calls = data_item.get(\"invalid_tool_calls\", [])\n",
    "                content = data_item.get(\"content\", \"\")\n",
    "                response_metadata = data_item.get(\"response_metadata\", {})\n",
    "\n",
    "                if content:\n",
    "                    print(f\"AI: {content}\")\n",
    "\n",
    "                if tool_calls:\n",
    "                    print(\"Tool Calls:\")\n",
    "                    print(format_tool_calls(tool_calls))\n",
    "\n",
    "                if invalid_tool_calls:\n",
    "                    print(\"Invalid Tool Calls:\")\n",
    "                    print(format_tool_calls(invalid_tool_calls))\n",
    "\n",
    "                if response_metadata:\n",
    "                    finish_reason = response_metadata.get(\"finish_reason\", \"N/A\")\n",
    "                    print(f\"Response Metadata: Finish Reason - {finish_reason}\")\n",
    "                    \n",
    "        print(\"-\" * 50)\n"
   ],
   "id": "48f9d48786e80c88"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
